{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Desktop/Causal Inference/Project/CausalDPO/PhD_StereoSet/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import tqdm\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Optional, Iterator, Callable, Union, Tuple\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_term = 'profession'\n",
    "\n",
    "\n",
    "terms = []\n",
    "with open('data/dev.json', 'r') as file:\n",
    "    stero_train_data = json.load(file)\n",
    "\n",
    "with open('data/test.json', 'r') as file:\n",
    "    stero_test_data = json.load(file)\n",
    "\n",
    "new_data = []\n",
    "\n",
    "tasks = ['intersentence', 'intrasentence']\n",
    "for task in tasks:\n",
    "    for data in stero_train_data['data'][task]:\n",
    "        if data['bias_type'] == target_term:\n",
    "            \n",
    "            if data['target'] not in terms:\n",
    "                terms.append(data['target'])\n",
    "            prompt = data['context']\n",
    "            chosen = \"\"\n",
    "            rejected = \"\"\n",
    "            for sentence in data['sentences']:\n",
    "                if sentence['gold_label'] == 'anti-stereotype':\n",
    "                    chosen = sentence['sentence']\n",
    "                elif sentence['gold_label'] == 'stereotype':\n",
    "                    rejected = sentence['sentence']\n",
    "                \n",
    "            new_data.append({\n",
    "                'prompt': prompt,\n",
    "                'chosen': chosen,\n",
    "                'rejected': rejected,\n",
    "            })\n",
    "\n",
    "for task in tasks:\n",
    "    for data in stero_test_data['data'][task]:\n",
    "        if data['bias_type'] == target_term:\n",
    "            \n",
    "            if data['target'] not in terms:\n",
    "                terms.append(data['target'])\n",
    "            prompt = data['context']\n",
    "            chosen = \"\"\n",
    "            rejected = \"\"\n",
    "            for sentence in data['sentences']:\n",
    "                if sentence['gold_label'] == 'anti-stereotype':\n",
    "                    chosen = sentence['sentence']\n",
    "                elif sentence['gold_label'] == 'stereotype':\n",
    "                    rejected = sentence['sentence']\n",
    "                \n",
    "            new_data.append({\n",
    "                'prompt': prompt,\n",
    "                'chosen': chosen,\n",
    "                'rejected': rejected,\n",
    "            })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/{target_term}_data.json\", \"w\") as f:\n",
    "    json.dump(new_data, f, indent=2)\n",
    "\n",
    "with open(f\"data/{target_term}_terms.json\", \"w\") as f:\n",
    "    json.dump(terms, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
